import streamlit as st
import pandas as pd
from datetime import datetime
import os
import io
import fitz  # PyMuPDF
import docx

st.set_page_config(page_title="documents analyze", layout="wide")

st.title("ğŸ“¥ documents analyze")
st.markdown(":green[ì§€ì‹ ê¸°ë°˜ ìë™ í•´ì„ ë„êµ¬]ì…ë‹ˆë‹¤. ê·œì¹™ê³¼ ê°œë… ë°ì´í„°ë¥¼ ì—…ë¡œë“œí•˜ê³  ì¡°ê±´ì„ ì…ë ¥í•˜ê±°ë‚˜ ë¬¸ì„œë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")

# Upload document files (PDF, TXT, DOCX)
st.subheader("ğŸ“ ë¬¸ì„œ ì—…ë¡œë“œ ë° ë¯¸ë¦¬ë³´ê¸°")
uploaded_files = st.file_uploader("PDF / TXT / Word íŒŒì¼ ì—…ë¡œë“œ", type=["pdf", "txt", "docx"], accept_multiple_files=True)

def extract_text_from_pdf(file):
    with fitz.open(stream=file.read(), filetype="pdf") as doc:
        text = ""
        for page in doc:
            text += page.get_text()
        return text

def extract_text_from_docx(file):
    doc = docx.Document(file)
    text = "
".join([para.text for para in doc.paragraphs])
    return text

if uploaded_files:
    for uploaded_file in uploaded_files:
        st.markdown(f"### ğŸ“„ íŒŒì¼: `{uploaded_file.name}`")
        file_ext = uploaded_file.name.split('.')[-1].lower()
        content = ""
        try:
            if file_ext == "pdf":
                content = extract_text_from_pdf(uploaded_file)
            elif file_ext == "txt":
                content = uploaded_file.read().decode("utf-8")
            elif file_ext == "docx":
                content = extract_text_from_docx(uploaded_file)
            else:
                st.warning("ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤.")
            if content:
                st.text_area("ğŸ“œ ë¯¸ë¦¬ë³´ê¸°", content[:3000], height=300)
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

# Upload rules and concepts CSVs
log_file = "results.csv"
if os.path.exists(log_file):
    result_log = pd.read_csv(log_file)
else:
    result_log = pd.DataFrame(columns=["timestamp", "day", "branch", "element", "result"])

concept_file = st.file_uploader("ğŸ§  ê°œë… CSV ì—…ë¡œë“œ", type="csv")
rule_file = st.file_uploader("ğŸ“‹ ê·œì¹™ CSV ì—…ë¡œë“œ", type="csv")

if concept_file:
    concepts_df = pd.read_csv(concept_file)
    st.subheader("ğŸ“˜ ê°œë… í…Œì´ë¸”")
    filter_type = st.selectbox("ìœ í˜• í•„í„°", options=["ì „ì²´"] + sorted(concepts_df["type"].unique()))
    if filter_type == "ì „ì²´":
        st.dataframe(concepts_df)
    else:
        st.dataframe(concepts_df[concepts_df["type"] == filter_type])

if rule_file:
    rules_df = pd.read_csv(rule_file)
    st.subheader("ğŸ“— ê·œì¹™ í…Œì´ë¸”")
    filter_topic = st.selectbox("ì£¼ì œ í•„í„°", options=["ì „ì²´"] + sorted(rules_df["topic"].dropna().unique()))
    if filter_topic == "ì „ì²´":
        st.dataframe(rules_df)
    else:
        st.dataframe(rules_df[rules_df["topic"] == filter_topic])

    st.markdown("---")
    st.subheader("ğŸ” ìë™ í•´ì„ ì‹¤í–‰")

    with st.form("input_form"):
        col1, col2, col3 = st.columns(3)
        with col1:
            day = st.text_input("ì¼ê°„ (ì˜ˆ: ê°‘æˆŒ)", key="day")
        with col2:
            branch = st.text_input("ì‹œì§€ (ì˜ˆ: å¯…)", key="branch")
        with col3:
            element = st.text_input("ìì‹ì„± (ì˜ˆ: ä¸)", key="element")
        submitted = st.form_submit_button("ğŸ§  í•´ì„ ì‹¤í–‰")

    if submitted:
        if not all([day, branch, element]):
            st.warning("âš ï¸ ëª¨ë“  ì…ë ¥ê°’ì„ ì±„ì›Œì£¼ì„¸ìš”.")
        else:
            matched = rules_df[
                rules_df["condition"].astype(str).str.contains(day, na=False) |
                rules_df["condition"].astype(str).str.contains(branch, na=False) |
                rules_df["condition"].astype(str).str.contains(element, na=False)
            ]

            summary = ""
            if not matched.empty:
                invalids = matched[matched["topic"] == "invalidation"]
                overrides = matched[matched["topic"] == "override"]
                base = matched[~matched["topic"].isin(["invalidation", "override"])]

                if not invalids.empty:
                    st.error("ğŸš« ìì‹ ì—†ìŒ íŒì • (ë¬´íš¨í™” ê·œì¹™ ì ìš©)")
                    st.dataframe(invalids[["rule_id", "condition", "outcome"]])
                    summary = f"ë¬´íš¨í™” ì ìš©: {invalids['rule_id'].iloc[0]}"
                elif not overrides.empty:
                    st.warning("ğŸ” ì„±ë³„ ì „í™˜ ë˜ëŠ” ìš°ì„  íŒì •")
                    st.dataframe(overrides[["rule_id", "condition", "outcome"]])
                    summary = f"ì„±ë³„ ì „í™˜: {overrides['rule_id'].iloc[0]}"
                elif not base.empty:
                    st.success("âœ… ì¼ë°˜ í•´ì„ ê·œì¹™ ì ìš©")
                    st.dataframe(base[["rule_id", "condition", "outcome"]])
                    summary = f"ì¼ë°˜ ì ìš©: {base['rule_id'].iloc[0]}"
                else:
                    st.info("ğŸ” í•´ë‹¹ ì¡°ê±´ì— ì ìš©ë˜ëŠ” ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
                    summary = "í•´ë‹¹ ì—†ìŒ"
            else:
                st.info("ğŸ” í•´ë‹¹ ì¡°ê±´ì— ì ìš©ë˜ëŠ” ê·œì¹™ì´ ì—†ìŠµë‹ˆë‹¤.")
                summary = "í•´ë‹¹ ì—†ìŒ"

            # Save result
            timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
            result_log.loc[len(result_log)] = [timestamp, day, branch, element, summary]
            result_log.to_csv(log_file, index=False)
            st.success(f"ğŸ“Œ ê²°ê³¼ ì €ì¥ ì™„ë£Œ ({log_file})")

    st.markdown("---")
    st.subheader("ğŸ“Š ì´ì „ í•´ì„ ê¸°ë¡")
    st.dataframe(result_log)

# -------------------------------
# ğŸ“Œ ê°œë… / ê·œì¹™ ì •ê·œì‹ ê¸°ë°˜ ì¶”ì¶œ í•¨ìˆ˜
# -------------------------------

st.markdown("---")
st.subheader("ğŸ§  ë¬¸ì„œì—ì„œ ê°œë… ë° ê·œì¹™ ìë™ ì¶”ì¶œ (ì •ê·œì‹ ê¸°ë°˜)")

def extract_structured_data(text):
    concept_pattern = r"ê°œë…[:ï¼š]?\s*(.+)"
    rule_pattern = r"ê·œì¹™[:ï¼š]?\s*(.+)"
    condition_pattern = r"ì¡°ê±´[:ï¼š]?\s*(.+)"
    outcome_pattern = r"ê²°ê³¼[:ï¼š]?\s*(.+)"
    exception_pattern = r"ì˜ˆì™¸[:ï¼š]?\s*(.+)"

    lines = text.split("\n")
    extracted_data = []

    current_rule = {}
    for line in lines:
        line = line.strip()
        if not line:
            continue
        if match := re.match(rule_pattern, line):
            if current_rule:
                extracted_data.append(current_rule)
                current_rule = {}
            current_rule["rule"] = match.group(1)
        elif match := re.match(condition_pattern, line):
            current_rule["condition"] = match.group(1)
        elif match := re.match(outcome_pattern, line):
            current_rule["outcome"] = match.group(1)
        elif match := re.match(exception_pattern, line):
            current_rule["exception"] = match.group(1)
        elif match := re.match(concept_pattern, line):
            extracted_data.append({"concept": match.group(1)})

    if current_rule:
        extracted_data.append(current_rule)

    return pd.DataFrame(extracted_data)

# ì‹¤ì œ íŒŒì¼ì—ì„œ ì¶”ì¶œ ì‹¤í–‰
for uploaded_file in uploaded_files:
    file_ext = uploaded_file.name.split('.')[-1].lower()
    text = ""
    try:
        if file_ext == "pdf":
            text = extract_text_from_pdf(uploaded_file)
        elif file_ext == "txt":
            text = uploaded_file.read().decode("utf-8")
        elif file_ext == "docx":
            text = extract_text_from_docx(uploaded_file)

        if text:
            st.markdown(f"### ğŸ” `{uploaded_file.name}`ì—ì„œ ì¶”ì¶œëœ ë°ì´í„°")
            extracted_df = extract_structured_data(text)
            if not extracted_df.empty:
                st.dataframe(extracted_df)
                csv = extracted_df.to_csv(index=False).encode('utf-8')
                st.download_button("â¬‡ï¸ ì¶”ì¶œ ê²°ê³¼ CSV ë‹¤ìš´ë¡œë“œ", data=csv, file_name="extracted_rules_concepts.csv", mime="text/csv")
            else:
                st.warning("ğŸ“­ íŒ¨í„´ì— ë§ëŠ” ê·œì¹™ ë˜ëŠ” ê°œë…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    except Exception as e:
        st.error(f"âŒ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
